{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.Encoder import Encoder\n",
    "from model.Decoder import Decoder\n",
    "from model.Generator import Generator\n",
    "from model.Transformer import Transformer\n",
    "\n",
    "from typing import List, Tuple, Union\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 25\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'fr_core_news_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_en(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Translates English text sequence into a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The English text sequence to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of tokens representing the English text.\n",
    "    \"\"\"\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_fr(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Translates French text sequence into a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The French text sequence to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of tokens representing the French text.\n",
    "    \"\"\"\n",
    "    return [token.text for token in spacy_fr.tokenizer(text)]\n",
    "\n",
    "PAD_TOKEN = '<pad>'  #  represents the padding token used to fill sequences of different lengths to make them equal in length during batching or processing.\n",
    "SOS_TOKEN = '<s>'  # represents the start-of-sentence token, indicating the beginning of a sentence.\n",
    "EOS_TOKEN = '</s>'  # represents the end-of-sentence token, indicating the end of a sentence.\n",
    "UNK_TOKEN = '<unk>'  # represents the unknown token, used to represent words or tokens that are out-of-vocabulary or unknown.\n",
    "\n",
    "# english text field\n",
    "en_text = Field(\n",
    "    tokenize=tokenize_en, lower=True, include_lengths=True, batch_first=True,\n",
    "    pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN, unk_token=UNK_TOKEN,\n",
    ")\n",
    "\n",
    "# french text field\n",
    "fr_text = Field(\n",
    "    tokenize=tokenize_fr, lower=True, include_lengths=True, batch_first=True,\n",
    "    pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN, unk_token=UNK_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fields = (('src', en_text), ('trg', fr_text))\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.fr'), fields=data_fields)\n",
    "#  the source language (English) and target language (french) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the english and french vocabulary\n",
    "en_text.build_vocab(train_data.src, max_size=10000, min_freq=2)\n",
    "fr_text.build_vocab(train_data.trg, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary: 5893 words\n",
      "french vocabulary: 6470 words\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = fr_text.vocab.stoi[PAD_TOKEN]\n",
    "SOS_IDX = fr_text.vocab.stoi[SOS_TOKEN]\n",
    "EOS_IDX = fr_text.vocab.stoi[EOS_TOKEN]\n",
    "UNK_IDX = fr_text.vocab.stoi[UNK_TOKEN]\n",
    "\n",
    "\"\"\"\n",
    "These variables can be useful when working with the french vocabulary to access specific token indices.\n",
    "For example, you can use PAD_IDX to identify the index of the padding token when processing french sequences,\n",
    "or use SOS_IDX and EOS_IDX to mark the start and end of sequences during inference or evaluation.\n",
    "Similarly, UNK_IDX can be used to handle out-of-vocabulary or unknown tokens in the french text.  \n",
    "\"\"\"\n",
    "\n",
    "print(f'English vocabulary: {len(en_text.vocab)} words')\n",
    "print(f'french vocabulary: {len(fr_text.vocab)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training examples: 29000\n",
      "# of validation examples: 1014\n",
      "# of testing examples: 1000\n",
      "dict_keys(['src', 'trg'])\n",
      "dict_values([['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.'], ['deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'prÃ¨s', 'de', 'buissons', '.']])\n"
     ]
    }
   ],
   "source": [
    "print(f'# of training examples: {len(train_data.examples)}')\n",
    "print(f'# of validation examples: {len(valid_data.examples)}')\n",
    "print(f'# of testing examples: {len(test_data.examples)}')\n",
    "\n",
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': torch.Size([64, 11]), 'source_lengths': torch.Size([64])}\n",
      "{'target': torch.Size([64, 16]), 'target_lengths': torch.Size([64])}\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see if data loader is working\n",
    "x = next(iter(train_iterator))\n",
    "\n",
    "print({'source': x.src[0].shape, 'source_lengths': x.src[1].shape})\n",
    "print({'target': x.trg[0].shape, 'target_lengths': x.trg[1].shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model:nn.Module):\n",
    "    \"\"\"\n",
    "    Prints a summary of the model, including the number of trainable and non-trainable parameters.\n",
    "\n",
    "    Args:\n",
    "        model (Transformer): The transformer model.\n",
    "    \"\"\"\n",
    "    print(model)\n",
    "    print(f'# of trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "    print(f'# of non-trainable params: {sum(p.numel() for p in model.parameters() if not p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ids_to_text(ids: torch.Tensor, vocab: torchtext.vocab.Vocab, eos_idx: int, unk_idx: int) -> Union[List[str], List[List[str]]]:\n",
    "\n",
    "    \"\"\"\n",
    "    Converts token ids to text.\n",
    "\n",
    "    Args:\n",
    "        ids (torch.Tensor): The token ids to be converted.\n",
    "        vocab (torchtext.vocab.Vocab): The vocabulary object.\n",
    "        eos_idx (int): The index representing the end-of-sentence token.\n",
    "        unk_idx (int): The index representing the unknown token.\n",
    "\n",
    "    Returns:\n",
    "        Union[List[str], List[List[str]]]: The converted tokens as a list of strings\n",
    "        or a list of lists of strings, depending on the input dimensions.\n",
    "    \"\"\"\n",
    "    if ids.dim() == 1:\n",
    "        output_tokens = []\n",
    "        for token_id in ids:\n",
    "            if token_id == eos_idx:\n",
    "                break\n",
    "            else:\n",
    "                output_tokens.append(vocab.itos[token_id])\n",
    "        return output_tokens\n",
    "    \n",
    "    elif ids.dim() == 2:\n",
    "        return [convert_ids_to_text(ids[i, :], vocab, eos_idx, unk_idx) for i in range(ids.size(0))]\n",
    "    \n",
    "    raise RuntimeError(f'ids has {ids.size()} dimensions, expected 2 dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOptim(object):\n",
    "    \"\"\"\n",
    "    Optimizer wrapper for learning rate scheduling.\n",
    "\n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): The base optimizer.\n",
    "        d_model (int): The model's hidden size.\n",
    "        factor (int): The factor used to compute the learning rate.\n",
    "        n_warmup_steps (int): The number of warm-up steps for the learning rate.\n",
    "\n",
    "    Methods:\n",
    "        zero_grad(): Clears the gradients of all optimized parameters.\n",
    "        step(): Updates the parameters and performs optimization.\n",
    "        get_lr(): Computes the learning rate at the current step.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: optim.Adam, d_model: int, factor: int, n_warmup_steps: int):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.factor = factor\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_steps = 0\n",
    "    \n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        self.n_steps += 1\n",
    "        lr = self.get_lr()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = lr\n",
    "        self.optimizer.step()\n",
    "\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.factor * (\n",
    "            self.d_model ** (-0.5)\n",
    "            * min(self.n_steps ** (-0.5), self.n_steps * self.n_warmup_steps ** (-1.5))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model: nn.Module, iterator: BucketIterator, optimizer: NoamOptim, criterion: nn.CrossEntropyLoss, clip: float = 1.0) -> Tuple[torch.Tensor, float]:\n",
    "\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (Transformer): The transformer model to be trained.\n",
    "        iterator (torchtext.data.Iterator): The iterator for training data.\n",
    "        optimizer (NoamOptim): The optimizer for parameter updates.\n",
    "        criterion (torch.nn.modules.loss._Loss): The loss criterion.\n",
    "        clip (float): The value used to clip the gradients to avoid exploding gradients.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, float]: The output predictions and perplexity.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "\n",
    "    tk0 = tqdm(iterator, total=len(iterator), position=0, leave=True)\n",
    "\n",
    "    for idx, batch in enumerate(tk0):\n",
    "        source, source_lengths = batch.src\n",
    "        target, target_lengths = batch.trg\n",
    "\n",
    "        # source: (batch_size, source_seq_len), source_lengths: (batch_size)\n",
    "        # target: (batch_size, target_seq_len), target_lengths: (batch_size)\n",
    "        \n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(source, target[:, :-1])  # (batch_size, target_seq_len - 1, vocab_size)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(\n",
    "            output.view(-1, output.size(-1)),  # (batch_size * (target_seq_len - 1), vocab_size)\n",
    "            target[:, 1:].contiguous().view(-1)  # (batch_size * (target_seq_len - 1))\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "\n",
    "        output = output.argmax(dim=-1)  # (batch_size, target_seq_len - 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients to avoid exploding gradients issue\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        tk0.set_postfix(loss=total_loss/steps)\n",
    "\n",
    "    tk0.close()\n",
    "\n",
    "    perplexity = np.exp(total_loss / len(iterator))\n",
    "    \n",
    "    return output, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model: nn.Module, iterator: BucketIterator, criterion: nn.CrossEntropyLoss, optimizer: NoamOptim) -> Tuple[torch.Tensor, float, float]:\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation or test data.\n",
    "\n",
    "    Args:\n",
    "        model (Transformer): The transformer model to be evaluated.\n",
    "        iterator (torchtext.data.Iterator): The iterator for validation or test data.\n",
    "        criterion (torch.nn.modules.loss._Loss): The loss criterion.\n",
    "        optimizer (NoamOptim): The optimizer (not used in evaluation).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, float, float]: The output predictions, perplexity, and BLEU-4 score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "\n",
    "    tk0 = tqdm(iterator, total=len(iterator), position=0, leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(tk0):\n",
    "            source, source_lengths = batch.src\n",
    "            target, target_lengths = batch.trg\n",
    "\n",
    "            # source: (batch_size, source_seq_len), source_lengths: (batch_size)\n",
    "            # target: (batch_size, target_seq_len), target_lengths: (batch_size)\n",
    "            \n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(source, target[:, :-1])  # (batch_size, target_seq_len - 1, vocab_size)\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(\n",
    "                output.view(-1, output.size(-1)),  # (batch_size * (target_seq_len - 1), vocab_size)\n",
    "                target[:, 1:].contiguous().view(-1)  # (batch_size * (target_seq_len - 1))\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            output = output.argmax(dim=-1)  # (batch_size, target_seq_len - 1)\n",
    "            target = target[:, 1:]  # (batch_size, target_seq_len - 1)\n",
    "\n",
    "            # converting the ids to tokens (used later for calculating BLEU score)\n",
    "            pred_tokens = convert_ids_to_text(output, fr_text.vocab, EOS_IDX, UNK_IDX)\n",
    "            target_tokens = convert_ids_to_text(target, fr_text.vocab, EOS_IDX, UNK_IDX)\n",
    "\n",
    "            hypotheses += pred_tokens\n",
    "            references += [[token] for token in target_tokens]\n",
    "\n",
    "            tk0.set_postfix(loss=total_loss/steps)\n",
    "\n",
    "    tk0.close()\n",
    "\n",
    "    perplexity = np.exp(total_loss / len(iterator))\n",
    "    bleu4 = bleu_score(hypotheses, references)\n",
    "    \n",
    "    return output, perplexity, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "INPUT_SIZE = len(en_text.vocab)  # source vocab size\n",
    "OUTPUT_SIZE = len(fr_text.vocab)  # target vocab size\n",
    "HIDDEN_SIZE = 512\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 8\n",
    "FF_SIZE = 2048\n",
    "DROPOUT_RATE = 0.1\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (tok_embedding): Embedding(5893, 512, padding_idx=1)\n",
      "    (pos_embedding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x EncoderLayer(\n",
      "        (self_attention): MultiHeadAttentionLayer(\n",
      "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (self_attention_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (positionwise_feedforward): PositionWiseFeedForwardLayer(\n",
      "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ff_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (tok_embedding): Embedding(6470, 512, padding_idx=1)\n",
      "    (pos_embedding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x DecoderLayer(\n",
      "        (self_attention): MultiHeadAttentionLayer(\n",
      "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (self_attention_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (encoder_attention): MultiHeadAttentionLayer(\n",
      "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (enc_attention_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (positionwise_feedforward): PositionWiseFeedForwardLayer(\n",
      "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ff_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (proj): Linear(in_features=512, out_features=6470, bias=True)\n",
      "  )\n",
      ")\n",
      "# of trainable params: 53,787,462\n",
      "# of non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(INPUT_SIZE, HIDDEN_SIZE, N_LAYERS, N_HEADS, FF_SIZE, PAD_IDX, DROPOUT_RATE)\n",
    "decoder = Decoder(OUTPUT_SIZE, HIDDEN_SIZE, N_LAYERS, N_HEADS, FF_SIZE, PAD_IDX, DROPOUT_RATE)\n",
    "generator = Generator(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "model = Transformer(encoder, decoder, generator, PAD_IDX)\n",
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = NoamOptim(\n",
    "    optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9),\n",
    "    HIDDEN_SIZE, 2, 4000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bleu4 = float('-inf')\n",
    "es_patience = 3\n",
    "patience = 0\n",
    "model_path = 'model.pth'\n",
    "\n",
    "\n",
    "for epoch in range(0, N_EPOCHS):\n",
    "    # one epoch training\n",
    "    _, train_perplexity = train_fn(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    \n",
    "    # one epoch validation\n",
    "    _, valid_perplexity, valid_bleu4 = eval_fn(model, valid_iterator, criterion, optimizer)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Train perplexity: {train_perplexity:.4f}, Valid perplexity: {valid_perplexity:.4f}, Valid BLEU4: {valid_bleu4:.4f}')\n",
    "    \n",
    "    # early stopping\n",
    "    is_best = valid_bleu4 > best_bleu4\n",
    "    if is_best:\n",
    "        print(f'BLEU score improved ({best_bleu4:.4f} -> {valid_bleu4:.4f}). Saving Model!')\n",
    "        best_bleu4 = valid_bleu4\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "        print(f'Early stopping counter: {patience} out of {es_patience}')\n",
    "        if patience == es_patience:\n",
    "            print(f'Early stopping! Best BLEU4: {best_bleu4:.4f}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 16/16 [00:36<00:00,  2.27s/it, loss=3.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 26.8506, Test BlEU4: 0.1143\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test data\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "print('Evaluating the model on test data ...')\n",
    "_, test_perplexity, test_bleu4 = eval_fn(model, test_iterator, criterion, optimizer)\n",
    "print(f'Test perplexity: {test_perplexity:.4f}, Test BlEU4: {test_bleu4:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model: Transformer, sentence: Union[str, List[str]], max_len: int = 100) -> Tuple[List[str], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Performs greedy decoding to generate the translation of a given sentence.\n",
    "\n",
    "    Args:\n",
    "        model (Transformer): The transformer model.\n",
    "        sentence (str): The input sentence to be translated.\n",
    "        max_len (int): The maximum length of the generated translation.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated translation.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token.text.lower() for token in spacy_fr(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    token_ids = [SOS_IDX] + [en_text.vocab.stoi.get(token, UNK_TOKEN) for token in tokens] + [EOS_IDX]\n",
    "    \n",
    "    source = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0)  # (1, source_seq_len)\n",
    "    source_mask = model.get_pad_mask(source, PAD_IDX)  # (1, 1, source_seq_len)\n",
    "\n",
    "    # encode the source sequence\n",
    "    with torch.no_grad():\n",
    "        enc_output = model.encoder(source, source_mask)  # (1, source_seq_len, d_model)\n",
    "    \n",
    "    target_ids = [SOS_IDX]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        target = torch.tensor(target_ids, dtype=torch.long).unsqueeze(0)  # (1, target_seq_len)\n",
    "        target_mask = model.get_pad_mask(target, PAD_IDX) & model.get_subsequent_mask(target)\n",
    "\n",
    "        # decode the sequence\n",
    "        with torch.no_grad():\n",
    "            dec_output, attn = model.decoder(target, enc_output, source_mask, target_mask)\n",
    "\n",
    "            # dec_output: (1, target_seq_len, d_model)\n",
    "            # attn: (1, n_heads, target_seq_len, source_seq_len)\n",
    "\n",
    "            output = model.generator(dec_output)  # (1, target_seq_len, vocab_size)\n",
    "\n",
    "        target_id = output.argmax(dim=-1)[:, -1].item()\n",
    "        target_ids.append(target_id)\n",
    "\n",
    "        # stop decoding if we encounter EOS_TOKEN or reach the max length\n",
    "        if target_id == EOS_IDX or len(target_ids) >= max_len:\n",
    "            break\n",
    "        \n",
    "    target_tokens = [fr_text.vocab.itos[id] for id in target_ids]\n",
    "    attn = attn.squeeze(0).cpu().detach().numpy()  # (n_heads, target_seq_len, source_seq_len)\n",
    "\n",
    "    # target_tokens: list of size (target_seq_len - 1)\n",
    "    # attn: (n_heads, target_seq_len, source_seq_len)\n",
    "    \n",
    "    return target_tokens[1:], attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_scores(source: Union[str, List[str]], target: List[str], attention: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Plots the attention scores between the source and target tokens.\n",
    "\n",
    "    Args:\n",
    "        src_tokens (List[str]): The list of source tokens.\n",
    "        trg_tokens (List[str]): The list of target tokens.\n",
    "        attention_scores (torch.Tensor): The attention scores between the source and target tokens.\n",
    "            Shape: (target_length, source_length).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    n_heads = attention.shape[0]\n",
    "\n",
    "    if isinstance(source, str):\n",
    "        source = [token.lower for token in source.split(\" \")] + [EOS_TOKEN]\n",
    "    else:\n",
    "        source = [token.lower() for token in source] + [EOS_TOKEN]\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 12))\n",
    "\n",
    "    for h, head in enumerate(attention):\n",
    "        ax = fig.add_subplot(2, 4, h + 1)\n",
    "        x = source\n",
    "        y = target if h % 4 == 0 else []\n",
    "\n",
    "        sns.heatmap(\n",
    "            head, xticklabels=x, yticklabels=y, square=True,\n",
    "            vmin=0.0, vmax=1.0, cbar=False, cmap=\"Blues\", ax=ax,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ['a', 'man', 'is', 'smiling', 'at', 'a', 'stuffed', 'lion']\n",
      "\n",
      "target: ['ein', 'mann', 'lÃ¤chelt', 'einen', 'ausgestopften', 'lÃ¶wen', 'an', '.']\n",
      "\n",
      "predicted: ['ein', 'mann', 'lÃ¤chelt', 'an', 'einem', '<unk>', '.', '</s>']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXMAAAJsCAYAAAC/CzDDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAABFaklEQVR4nO3de5Rld1kn/O/TXUk65EYSIFzEtCiQCGIUyBIIiIqM4AWVuOAFXycOkNGZJQsHXK+jDKgMiig4QdSxQzDMDI4MEQERQ7jKNQMNuZEQUEkUAYPBBHLtdHf93j9qtxza7nRVpWrv+tX5fNY6q3ads/d+fvvsfZ469T27dlVrLQAAAAAAbGxbph4AAAAAAACHJswFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOjAwtQDWAs33b7Yxq751iu/MHbJ/MAp9x69ZpIctnX8zH+Kmott9MMob77i86PXfNIp9xm9Zsv4z+0Ux9Cx27bU6EUncvue8XfqX33mn8YumUc/4MTRa47/aklu2bVn9JrHH3X46DWnOIYecOLRo9fcdtg0n9Xf89gjRq+5bSFz0Xen6LlTOP70545e84aPvmr0mqyvCd7Sp+aiE81Pz7151/hH0RTH0Eve9dfjF03yb0+73+g1t9/zqNFrTpEvTOFvrrt59JoPmGB/7hk/dszxd9t60M7gzFwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA5siDC3qt5eVXefehwAAAAAABvVwtQDSJLW2pOnHgMAAAAAwEY2+pm5VfWTVfXRqrq0qv6wqrZW1bVVdY+q2l5Vn6qqc6vqyqq6qKqOHHuMAAAAAAAbzahhblWdmuRpSR7TWjstyd4kz9xvtgcm+b3W2kOS3JjkqWOOEQAAAABgIxr7Mgvfl+ThST5WVUlyZJIv7TfPNa21S4fpjyfZPtbgAAAAAAA2qrEvs1BJXtdaO224Pbi19iv7zbNrZnpvDhI4V9XZVbWzqnb+0Xk71mm4AAAAAAAbw9hn5r47yVuq6ndaa1+qqhOSHLOaFbXWdiTZkSQ33b7Y1nCMAAAAAAAbzqhhbmvtqqp6YZKLqmpLkt1J/uOYYwAAAAAA6NHYZ+amtfaGJG/Y7+7tw9frkzx0Zt7fHmlYAAAAAAAb2tjXzAUAAAAAYBWEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHViYegBr4bCF8TPpp377N4xe8/jH/dLoNZPkn//q10evWTV6yWydoOgUx9HexTZ6za1bJtihrKs2/mGUR3/ziaPX3L1n/A1d2Dr+6+WwreP/HN2zd/zndopj6Onn7xy95m//yENGr5kk92hHTFKXTaQtTj0CNoEpfo+Au2qK4/Zb73Xk+EWT3Pvu20av2ab45WUCUxxHX77ljvGLTmD7PY6aeghfx5m5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0IG7FOZW1faqurqqzq+qz1TV66vqCVX1oar666o6fbh9pKouqaoPV9WDh2XPqqo3VdWFw7wvn1nvzVX10qq6rKourqqT7uqGAgAAAAD0bC3OzP2WJK9Icspwe0aSM5K8IMkvJbk6yWNba9+R5EVJfn1m2dOSPC3JtyV5WlXdf7j/qCQXt9a+Pcn7kzxnDcYJAAAAANCthTVYxzWttSuSpKquTPLu1lqrqiuSbE9yXJLXVdUDk7Qkh80s++7W2leGZa9KcnKSzyW5I8nbhnk+nuT712CcAAAAAADdWoszc3fNTC/OfL+YpbD4JUne21p7aJIfTrLtIMvuzdfC5d2ttXaA+/9FVZ1dVTuraud55+6461sBAAAAALCBrcWZuYdyXJLPD9NnrdVKW2s7kuxIktv3pB1idgAAAACArq3FmbmH8vIkv1FVl2Sc8BgAAAAAYNO5S+Fqa+3aJA+d+f6sgzz2oJnFXjg8fn6S82fm/6GZ6aNnpi9IcsFdGScAAAAAQO/GODMXAAAAAIC7SJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANCBaq1NPYa77PY96X8jNrApDpH7/bs/Hr3m3/z3p41e825HbB295m137B295t7F8Q+io7ctjF5z20Jq9KIT0Xc3l+PP+P9Gr3nDB39z9JpT2L13cfSah22dn8/q56Xv6rmby/2f84bRa17+335s9JpJcvxRh49e86u37R695lFHjP++c+uW8dvfvPTcW3dP8BvwFF1+or25Z+/4G3vOBz87es3nnH7y6DWPneB34L+57pbRa7YJXjAPuvcxo9c88rCDv0rn590+AAAAAEDHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHlhXmVtXNM9O/VlVPqKpXVdUjDrHc+VV15koGtK9WVW2vqmesZFkAAAAAgM1qYaULtNZeNEy+a43Hsr/tSZ6R5I/XuQ4AAAAAwIa3osssVNWxVfWeqvpEVV1eVU+Zeeynhvsuq6r/ObPY46rqw1X12dmzdKvqF6rqY8Myv3qAci9L8tiqurSqfn7FWwYAAAAAsIms9Mzc25L8aGvtq1V1jyQXV9Vbk3xrkhcmeXRr7fqqOmFmmfskOSPJKUnemuSCqnpikgcmOT1JJXlrVT2utfb+meV+MckLWms/tKotAwAAAADYRFZ8mYUkv15Vj0uymOR+SU5K8r1J3thauz5JWmv/PDP/m1tri0muqqqThvueONwuGb4/Okvh7myYCwAAAADAYEWXWUjyzCT3TPLw1tppSa5Lsu0Qy+yama6Zr7/RWjttuH1La+28lQykqs6uqp1VtfO8c3esZFEAAAAAgO6s9Mzc45J8qbW2u6q+J8nJw/3vSfJnVfXK1tqXq+qE/c7O3d87krykql7fWru5qu6XZHdr7Usz89yU5JiDraC1tiPJjiS5fU/aCrcDAAAAAKArKz0z9/VJHlFVVyT5qSRXJ0lr7cokL03yV1V1WZJX3tlKWmsXJfnjJB8Z1nVB/nVwe3mSvcM/VPMP0AAAAACAubasM3Nba0cPX69P8qiDzPO6JK/b776zDrSeYfqcJOfcSa3dWboWLwAAAADA3FvpmbkAAAAAAExAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0IGFqQfQq9bGr1k1fs2p6l6z4+mj13z8y983es0P/9L3jl5zz+L4B+8/3nj76DUfeO+jR6/J5rM4QbPfMkHT/egF/2X0mqe+4C9Gr/mp3/7B0WtOYe8EfT5Jtm6Z6I0K62LP3vGPo4Wt83EMPeTb7z96zeOOPGz0msk0x9E/3rhr9JrHH7U4es17HnvE6DXnxRQ/R6f4Gbo4/mGbZJpe/133u/voNafof5ngx+j1t4zfc+922NbRa07xe+Gd7VBn5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHJg1zq+rNVfXxqrqyqs4e7ru5ql5aVZdV1cVVddKUYwQAAAAA2AimPjP337XWHp7kEUmeW1UnJjkqycWttW9P8v4kz5lygAAAAAAAG8HUYe5zq+qyJBcnuX+SBya5I8nbhsc/nmT7NEMDAAAAANg4Jgtzq+rxSZ6Q5FHDWbiXJNmWZHdrrQ2z7U2ycJDlz66qnVW187xzd4wwYgAAAACA6RwwKB3JcUluaK3dWlWnJPmulSzcWtuRZEeS3L4n7RCzAwAAAAB0bcrLLFyYZKGqPpXkZVm61AIAAAAAAAcw2Zm5rbVdSZ50gIeOnpnngiQXjDYoAAAAAIANaup/gAYAAAAAwDIIcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADoQLXWph7DXXb7noy+EXsXx3/etm6p0WtO5Y49i6PX/Mqtu0evecLRh49e86bb94xe84xfe9foNT/5sieNXnPbQubmRTpF312c4OfVlhp/l06xnVO8FXjXp68bveb3n3LS6DV37R7/59lZr79k9JpJ8oaffsToNeel707Rcz/1+ZvGLpkH3efo0WtO0OYz/t5Mtkz0e8QUx9EUv6ddd8vto9f8vlPuNXpNPXf9bIJYZtmm6LtT5AtT9KJth20dveafXv4Po9d839/cOHrN3/3xh45e88jDDt5znZkLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0YM3C3Kp6e1Xdfa3WBwAAAADA1yys1Ypaa09eq3UBAAAAAPD1VnVmblX9ZFV9tKourao/rKqtVXVtVd2jqrZX1aeq6tyqurKqLqqqI4flvrmqLqyqj1fVB6rqlOH+86vqD6rq4qr6bFU9vqpeO6zn/DXcXgAAAACALq04zK2qU5M8LcljWmunJdmb5Jn7zfbAJL/XWntIkhuTPHW4f0eSn2utPTzJC5L8/swyxyd5VJKfT/LWJL+T5CFJvq2qTlvpOAEAAAAANpPVXGbh+5I8PMnHqipJjkzypf3muaa1dukw/fEk26vq6CSPTvLGYbkkOWJmmT9vrbWquiLJda21K5Kkqq5Msj3JpQEAAAAAmFOrucxCJXlda+204fbg1tqv7DfPrpnpvVkKjbckuXFmudNaa6ceYJnF/ZZfzAFC56o6u6p2VtXO887dsYrNAAAAAADox2rOzH13krdU1e+01r5UVSckOeZQC7XWvlpV11TVT7TW3lhLp+c+rLV22SrGkNbajixdtiG370lbzToAAAAAAHqx4jNzW2tXJXlhkouq6vIk70xyn2Uu/swkz6qqy5JcmeQpK60PAAAAADCPVnNmblprb0jyhv3u3j58vT7JQ2fm/e2Z6WuS/MAB1nfWzPS1+y1/1v7zAwAAAADMm9VcMxcAAAAAgJEJcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADowMLUA+jV1i019RA2tSme3dt27x295hTH0eJiG73m4YdvHb0mm8+Wmo++O8l2TlDy1X917eg1/82p9x695hR9/pmPvO/oNdl8Tr3fMVMPYdMa/51YstimqDrNcfTwF180es0/+LePGL0mm8ucvM2dzGFbxz+PcWHL+H13iuPojO33GL3mz/zmu0av+eqnPnT0mnfGmbkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHRg9zq2p7VX1y7LoAAAAAAD1bVZhbVYdX1VFrOZCqOqqqDlvLdQIAAAAAbBYrCnOr6tSqekWSTyd50HDftVV1j2H6EVX1vmH6V6rqtVX1vqr6bFU99wDre0BVXVJVjxzW95mq+u2qOvUubhcAAAAAwKZyyDB3OGP2p6vqg0nOTXJVkoe11i5ZxvpPSfJvkpye5MWzZ95W1YOT/GmSs1prHxvW97AkVyd5TVV9cKi7pmcAAwAAAAD0aGEZ83wxyeVJnt1au3qF6/+L1tquJLuq6ktJThruv2eStyT58dbaVftmbq3dlOQ1WQpzT01yXpJzkhy7wroAAAAAAJvKci6zcGaSzyd5U1W9qKpO3u/xPTPr2bbfY7tmpvfma+HxV5L8fZIz9i82/IO0Fyf5sySfG+r/K1V1dlXtrKqd5527YxmbAQAAAADQr0OemdtauyjJRVV1YpKfTPKWqro+S2fqXpvk2iQPT/KXSZ66zLp3JPmxJO+oqptba39cVduzdFbuPZL8UZLHtNa+fCfj2pFkR5LcvidtmXUBAAAAALq0nMssJEmGYPWcJOdU1elZOtM2SX41yXlV9ZIk71vB+m6pqh9K8s6qujnJJUl+qbX20eWuAwAAAABgXiw7zJ01G7i21j6Q5EEHmOdX9vv+oTPfPnS478Ykj5y5/3OrGQ8AAAAAwGa3nGvmAgAAAAAwMWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB1YmHoAcCD/5/J/GL3mKccfM3rNbzzxbqPX3FI1es3f/7ePGL0msHxX/cNXR685QSuaxB17Fkev+eiTTxy9JrB8/3zLHaPXPPbIaX7t27J1/GZ//XVfGb3mqfc9dvSarJ/dE/zsXtjqPLv1dM0/3TJ6zXsde8ToNY86Yvxe//dfvnX0mi/62ceOXnPvYhu9ZnLwn6E6BgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB7oNc6vq7KraWVU7zzt3x9TDAQAAAABYVwtTD2C1Wms7kuxIktv3pE08HAAAAACAdbXhz8ytqrdX1X2nHgcAAAAAwJQ2/Jm5rbUnTz0GAAAAAICpbfgzcwEAAAAAEOYCAAAAAHRBmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0IFqrU09hrvs+pv3jL4RW7fU2CWz7bCto9dMkptv3zN6zS/ceNvoNQ9fGP+zjXsft230mrt2L45e85p/umX0mt9y0tGj17znMQvjN4aJfOW2xdH7bsv4P6+m+BFZExxFL33334xe8z899ptGr3nk4eP/HL1jz/g999Zde0evmSQnHH346DWP3TbBG7IJXHP97aN3o5OOPWLsktk7QdPds3f8mh/+7JdHr/ld33TC6DWT5MgJfn/5u+tvHb3mERNs58LW8dvfN55wxFz03C/ceMfojWGK30WnMsV7oymylC99ddfoNe9xzPjvxb544+2j1zxm28LoNafIAO9/Jz13fjoGAAAAAEDHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHRg1zq+rpVfXLY9YEAAAAANgM1jXMrarDq+qombuelOTCZc4LAAAAAMBgXcLcqjq1ql6R5NNJHjTcV0lOS/KJqvruqrp0uF1SVcckOT7JlVX1h1X1yPUYFwAAAABAr9YszK2qo6rqp6vqg0nOTXJVkoe11i4ZZvmOJJe11lqSFyT5j62105I8NsltrbXrkjw4yXuTvHQIeZ9bVSes1RgBAAAAAHq1lmfmfjHJs5I8u7V2RmvtvNbaTTOP/0CSvxymP5TklVX13CR3b63tSZLW2q7W2p+01p6Y5ClJnpDkC1V13/2LVdXZVbWzqnb+j9eeu4abAQAAAACw8axlmHtmks8neVNVvaiqTt7v8ScmuShJWmsvS/LsJEcm+VBVnbJvpqq6V1U9P8mfJ9ma5BlJrtu/WGttR2vtEa21R/zUv3vOGm4GAAAAAMDGs7BWK2qtXZTkoqo6MclPJnlLVV2fpdD2hiQLrbUvJ0lVfXNr7YokVwzXxz2lqr6Y5HVJTknyP5M8ubX2+bUaHwAAAABAz9YszN1nCGzPSXJOVZ2eZG+S70/yrpnZnldV35NkMcmVWbr8wrYkr0ry3uG6ugAAAAAADNY8zJ3VWvtoklTVi5O8Zub+nzvA7LuSvGc9xwMAAAAA0Kt1DXP3aa09e4w6AAAAAACb1Vr+AzQAAAAAANaJMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOhAtdamHsOkqurs1toONdVUc2PWnWpbWR/zcgzNS82p6qq5uWqyfvQFNdVUk3HNy3Gk5uaqOVXdeam5HpyZm5ytpppqbui6U20r62NejqF5qTlVXTU3V03Wj76gpppqMq55OY7U3Fw1p6o7LzXXnDAXAAAAAKADwlwAAAAAgA4Ic5MprpWhppo91pyqbvfXs+HrzMsxNC81p6qr5uaqyfrRF9RUU03GNS/HkZqbq+ZUdeel5pqb+3+ABgAAAADQA2fmAgAAAAB0QJi7iVXVhyeoed+qumCYfnxVvW2Y/pGq+sURx/FLY9VaC1X1vKq62zLmu2dV/d+quqSqHltVP1FVn6qq966g1vlVdeYB7r95+Pov+3AqVfX0qvrlKccAK6Xn9kXf/bpx6Ll0aey+u1F67lCzq76r5/6rsei7dMd73X5shJ47PLYh+u5m7LnC3E2stfboCWp+obX2r17IrbW3ttZeNuJQumq2SZ6X5JDNNsn3JbmitfYdrbUPJHlWkue01r5nrQZysH24nqrq8Ko6auauJyW5cJnzwoag53bneZnTvqvnslmM3Xc3UM9N+uu7z8uc9txE32Vz8F63K8/LBum5ife662Fuw9yqenNVfbyqrqyqs9dondur6urhk4nPVNXrq+oJVfWhqvrrqjp9uH1k+OTjw1X14GHZs6rqTVV14TDvy9dgPPs+BblPVb2/qi6tqk9W1WOXsexRVfUXVXXZsMzTquraqvqNYT07q+o7q+odVfW3VfUzM8/BJw+wvrOq6tXD9PlV9aph+z+771OcqtpSVb8/PIfvrKq3H+wTnv3W/XX7sqpeluTIYZyvX+HTtiKrOY4O8Ny+OMl9k7x33ydg+/bdMH3m8JydluTlSZ4ybNuLk5yR5Lyq+q2q2jp8/VhVXV5V/35Yvqrq1VX16ap6V5J7HWJ8/7IPq2pbVf1RVV0xHLPfM9y/JsdrVZ1aVa9I8ukkD9o33iSnJflEVX33sK2XDvWPSXJ8kiur6g+r6pGrqcs01rrv6rl67gqW03ej586bzd5zh/Wuqu/21HOHZbvqu3ru19XSd+fEWvfcYZ0bqu+utucOy3TTd/Xcte25wzLe66611tpc3pKcMHw9Msknk5y4BuvcnmRPkm/LUlD+8SSvTVJJnpLkzUmOTbIwzP+EJH86TJ+V5LNJjkuyLcnfJbn/XRzPzcPX5yf55WF6a5JjlrHsU5OcO/P9cUmuTfKzw/e/k+TyJMckuWeS62aeg08O049P8raZ7Xv1MH1+kjcOz9G3Jvmb4f4zk7x9uP/eSW5IcuZq9uW+bd+Ix9GdPLf32H/fzTwv5+//PA7fvy/JI4bps5O8cJg+IsnOJN+U5MeTvHPY9/dNcuOBnteZ42V2Hz4/yWuH6VOS/P1wfK76eE1yVJKfTvLB4fas2WMyyXcm+R/D9J8necwwfXS+9to5IsnTk1yU5JIkz923L9w27m01r5dDrG979NzZ1+vjo+eu9Pnd9H03eu7c3lb7ermT9W3PBuq5w3pX1XfvpCdsuJ57sH2ZDdx37+T53fQ9d1iPvjuHt9W8Vpaxzu3ZQH033utuyOPoTp7bSXvufsfM7H70XncNbguZX8+tqh8bpu+f5IFJvrwG672mtXZFklTVlUne3VprVXVFlg7g45K8rqoemKQlOWxm2Xe31r4yLHtVkpOTfG4NxvSxJK+tqsOSvLm1dukylrkiySuq6jez1DA/sPSBRt468/jRrbWbktxUVbuq6u4rGNObW2uLSa6qqpOG+85I8sbh/n+s5V+n5UD7ciyrOY4O9tzeVU9M8rCZTxuPG8bzuCT/u7W2N8kXquo9K1jnGUl+N0laa1dX1d9l+IQrqz9ev5ilH9TPbq1dfYDHfyDJXw7TH0ryyuET0De11v5hGMuuJH+S5E+q6huTvDrJy6vqAa21L6xg+xjXevRdPXd55rnnJvPdd/Xc+TUvPTdZed/tqecm/fXdee65ib47r+QLd66nvqvnLlmPnpt4r7sm5vIyC1X1+Cx9avWo1tq3Zyl537ZGq981M7048/1ikoUkL0ny3tbaQ5P88H51Z5fdO8x/l7XW3p+lF9znk5xfVT+1jGU+k6VPMK5I8l+r6kX7jXF22/Z9v5Lxzi676k6zzvtyXWrfyXP7dbPNTC93eyrJz7XWThtu39Rau2iZy67Gao/XM7N0LL6pql5UVSfv9/gTs/SJWNrSdZCenaVPJj9UVafsm6mq7lVVz8/Sp2tbkzwjyXWr2RDW3zq+VvXc5ZnbnpvMfd/Vc+fQPPXcZOV9t5eem/TZd+e85yb67tyRL3ivuxb03CTe6y7bXIa5WfpE4YbW2q3DzvuukWt/fpg+a4yCw8F8XWvt3CSvydIL/VDL3DfJra21/5Xkt5azzBr4UJKn1tK1bU7K0p9RHMrB9uXu4ZPC9bSq4+ggz+1NWfqTkn2uq6XrvWxJ8mMHWM2BvCPJz+7b7qp6UC1dyPv9SZ5WS9e8uU+SlVzM/ANJnrlvfUm+MUvXn1m11tpFrbWnJXlskq8keUtVvauWrqNzXJb+1OHLQ81vbq1d0Vr7zSx9AnxKVR1XVW8etmtbkie31n6wtfam4dNBNqap+q6ee3Bz0XOT+e67eu7cmpuem6y873bUc5MO++4899xE351T8oVDL9NL39Vzv2Y9em7ive6amNfLLFyY5Geq6lNZOmguHrH2y7P0ZxAvTPIXI9V8fJJfqKrdSW5OcshPzrJ0XZ7fqqrFJLuT/GySC9ZthEv+NEv/TfGqLJ1K/4ksvRjvzMH25Y4kl1fVJ1prz1yn8a72ODrQc/uoJBdW1Rfa0n+O/MUkb0vyT1m6Ns3Ry1jva7L0pzafqKoalv3RJH+W5Huz9Lz+fZKPLHOcSfL7Sf6glv6MZ0+Ss1pru2oN/mxjaKjnJDmnqk7P0idv35/kXTOzPa+WLoi+mOTKLP15xLYkr8rSJ9At9GKqvqvnHty89NxE39Vz58889dxk5X23l56b9Nl3577nJvrunJEvHFovfVfP/Zr16LmJ97projoaK3Ogqo5urd1cVScm+WiWLk79j1OPi3FU1WuSvKa1NuYbIJhbeu5803NhXHou+i6MS9+db5u55wpz2VCq6n1J7p7k8CQvb62dP+V4ADYzPRdgPHouwLj0XTYrYS4AAAAAQAfm9R+gAQAAAAB0RZgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0YGHqAayFG27d28auefjC+Dn4Wz75+dFrJsnD73vC6DXvdewRo9c8bOv4+7Rq9JK55ku3jF7z+KMPH73mkYdtHb3mCUdtnWCPTuP2PRm9707h+O/+5dFr/tN7/uvoNRfm59Ad3WIb/6WyZYofLhPZtpC52Nibd41/IO3euzh2yXznL184es3LX/ak0WtO8RqdoBUlmeY4muJnWk3QiqZo9UcdPh8/YG65Y/xXzO9/+JqxS+Y/PPqbRq+ZZJIf3FO0wK1bxt/S3/3gZ0ev+ezTTx695hR53BTurOfOxzMAAAAAANA5YS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANCBDRHmVtXbq+ruU48DAAAAAGCjWph6AEnSWnvy1GMAAAAAANjIRj8zt6p+sqo+WlWXVtUfVtXWqrq2qu5RVdur6lNVdW5VXVlVF1XVkWOPEQAAAABgoxk1zK2qU5M8LcljWmunJdmb5Jn7zfbAJL/XWntIkhuTPHXMMQIAAAAAbERjn5n7fUkenuRjVXXp8P0D9pvnmtbapcP0x5NsP9CKqursqtpZVTvPf+256zNaAAAAAIANYuxr5laS17XW/vPX3Vl11sy3u2am9yY54GUWWms7kuxIkhtu3dvWdpgAAAAAABvL2GfmvjvJmVV1rySpqhOq6uSRxwAAAAAA0J1Rz8xtrV1VVS9MclFVbUmyO8l/HHMMAAAAAAA9GvsyC2mtvSHJG/a7e/vw9fokD52Z97dHGhYAAAAAwIY29mUWAAAAAABYBWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHhLkAAAAAAB0Q5gIAAAAAdECYCwAAAADQAWEuAAAAAEAHFqYewFpY2Fqj19y1e3H0mk944Emj10ySux0+/mGydcv4+3TvYhu95hTH0X/4P5eNXvMNz3rk6DUPX/BZ1WbTxn+JJlu2jl5yip9p82KKY2jP3vGLHr7gGNpspugLWyfof9/yzSeOXjMT9IWtE+zPxQne5ybJtsPGP44uuvofR6/5xFPuPXrN0urXzRRP7c88avvoNZ/1vy8dvWaSnPf/nDZ6zS1z8oKZ4jj6q7/+p9Frfu+D7zV6zSnyojvrRtIOAAAAAIAOCHMBAAAAADogzAUAAAAA6IAwFwAAAACgA8JcAAAAAIAOCHMBAAAAADogzAUAAAAA6IAwFwAAAACgA8JcAAAAAIAOCHMBAAAAADogzAUAAAAA6MBdCnOrantVXV1V51fVZ6rq9VX1hKr6UFX9dVWdPtw+UlWXVNWHq+rBw7JnVdWbqurCYd6Xz6z35qp6aVVdVlUXV9VJd3VDAQAAAAB6thZn5n5LklckOWW4PSPJGUlekOSXklyd5LGtte9I8qIkvz6z7GlJnpbk25I8raruP9x/VJKLW2vfnuT9SZ6zBuMEAAAAAOjWwhqs45rW2hVJUlVXJnl3a61V1RVJtic5LsnrquqBSVqSw2aWfXdr7SvDslclOTnJ55LckeRtwzwfT/L9azBOAAAAAIBurcWZubtmphdnvl/MUlj8kiTvba09NMkPJ9l2kGX35mvh8u7WWjvA/f+iqs6uqp1VtfOPXrPjrm8FAAAAAMAGthZn5h7KcUk+P0yftVYrba3tSLIjSW7atdgOMTsAAAAAQNfW4szcQ3l5kt+oqksyTngMAAAAALDp3KVwtbV2bZKHznx/1kEee9DMYi8cHj8/yfkz8//QzPTRM9MXJLngrowTAAAAAKB3Y5yZCwAAAADAXSTMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADoQLXWph7DXXb7nvS/EXyd4x/zC6PX/OcP/tboNatGL5nFTfCaX44tEzy52xYywR6dhr67uRz/qP80es1//vArR685Lz13iv43lXnpu3ru5nL8d/386DVvuPh3Rq85lSne6s5L29Vz6dWL3vHp0WvevGvv6DVf+SPfOnrNKczL++s767nOzAUAAAAA6IAwFwAAAACgA8JcAAAAAIAOCHMBAAAAADogzAUAAAAA6IAwFwAAAACgA8JcAAAAAIAOCHMBAAAAADogzAUAAAAA6MCywtyqunlm+teq6glV9aqqesQhlju/qs5cyYD21aqq7VX1jJUsCwAAAACwWS2sdIHW2ouGyXet8Vj2tz3JM5L88TrXAQAAAADY8FZ0mYWqOraq3lNVn6iqy6vqKTOP/dRw32VV9T9nFntcVX24qj47e5ZuVf1CVX1sWOZXD1DuZUkeW1WXVtXPr3jLAAAAAAA2kZWemXtbkh9trX21qu6R5OKqemuSb03ywiSPbq1dX1UnzCxznyRnJDklyVuTXFBVT0zywCSnJ6kkb62qx7XW3j+z3C8meUFr7YdWtWUAAAAAAJvIii+zkOTXq+pxSRaT3C/JSUm+N8kbW2vXJ0lr7Z9n5n9za20xyVVVddJw3xOH2yXD90dnKdydDXMBAAAAABis6DILSZ6Z5J5JHt5aOy3JdUm2HWKZXTPTNfP1N1prpw23b2mtnbeSgVTV2VW1s6p2nnfujpUsCgAAAADQnZWemXtcki+11nZX1fckOXm4/z1J/qyqXtla+3JVnbDf2bn7e0eSl1TV61trN1fV/ZLsbq19aWaem5Icc7AVtNZ2JNmRJLfvSVvhdgAAAAAAdGWlZ+a+PskjquqKJD+V5Ookaa1dmeSlSf6qqi5L8so7W0lr7aIkf5zkI8O6Lsi/Dm4vT7J3+Idq/gEaAAAAADDXlnVmbmvt6OHr9UkedZB5Xpfkdfvdd9aB1jNMn5PknDuptTtL1+IFAAAAAJh7Kz0zFwAAAACACQhzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6UK21qcdwl92+J/1vxDJMtaumOEa+95XvH73mRc977Og1D18Y//OUO/Ysjl7z6i/cNHrNh33jcaPX3LaQGr3oROal786LxcXxd+eJj3n+6DVv+MgrR6/J+pqXvqvnclft2j3++78kOeKw8d/rfvW23aPXPPn//aPRa95wwdmj19Rz6dWevePv0ns+4cWj17zhvb82es0pTPG7y5Yt47e/O+u5zswFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADkwa5lbVm6vq41V1ZVWdPdx3c1W9tKouq6qLq+qkKccIAAAAALARTH1m7r9rrT08ySOSPLeqTkxyVJKLW2vfnuT9SZ4z5QABAAAAADaCqcPc51bVZUkuTnL/JA9MckeStw2PfzzJ9mmGBgAAAACwcUwW5lbV45M8IcmjhrNwL0myLcnu1lobZtubZOEgy59dVTuraud55+4YYcQAAAAAANM5YFA6kuOS3NBau7WqTknyXStZuLW2I8mOJLl9T9ohZgcAAAAA6NqUl1m4MMlCVX0qycuydKkFAAAAAAAOYLIzc1tru5I86QAPHT0zzwVJLhhtUAAAAAAAG9TU/wANAAAAAIBlEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHSgWmtTj+Euu31PRt+IKZ62qfbV4gRl79izOHrNbYeN/9lGVY1e87NfumX0mk//7x8evebHXvz9o9fctpDxd+hEbrlj/IY0wcslWyYoOkWr/4d/vm30mgtbx39uTzruiNFrfuRvvzx6zb++4ebRaybJv33E9tFrHnnYfPTdKd7rsrlM9SvfFD+7b7tj7+g17/uDvz56zRve+V9Grzkv73VvvG3v6K+Yz//z7WOXnOR9UTJNX5giX5giR7nxlt2j1/yGE44cvebfXjf+e90HnHTU6DXvfuTBf2FyZi4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAfWLMytqrdX1d3Xan0AAAAAAHzNwlqtqLX25LVaFwAAAAAAX29VZ+ZW1U9W1Uer6tKq+sOq2lpV11bVPapqe1V9qqrOraorq+qiqjpyWO6bq+rCqvp4VX2gqk4Z7j+/qv6gqi6uqs9W1eOr6rXDes5fw+0FAAAAAOjSisPcqjo1ydOSPKa1dlqSvUmeud9sD0zye621hyS5MclTh/t3JPm51trDk7wgye/PLHN8kkcl+fkkb03yO0kekuTbquq0lY4TAAAAAGAzWc1lFr4vycOTfKyqkuTIJF/ab55rWmuXDtMfT7K9qo5O8ugkbxyWS5IjZpb589Zaq6orklzXWrsiSarqyiTbk1waAAAAAIA5tZrLLFSS17XWThtuD26t/cp+8+yamd6bpdB4S5IbZ5Y7rbV26gGWWdxv+cUcIHSuqrOramdV7Tzv3B2r2AwAAAAAgH6s5szcdyd5S1X9TmvtS1V1QpJjDrVQa+2rVXVNVf1Ea+2NtXR67sNaa5etYgxpre3I0mUbcvuetNWsAwAAAACgFys+M7e1dlWSFya5qKouT/LOJPdZ5uLPTPKsqrosyZVJnrLS+gAAAAAA82g1Z+amtfaGJG/Y7+7tw9frkzx0Zt7fnpm+JskPHGB9Z81MX7vf8mftPz8AAAAAwLxZzTVzAQAAAAAYmTAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADwlwAAAAAgA4IcwEAAAAAOiDMBQAAAADogDAXAAAAAKADC1MPoFctbfSaW7bU6DWTaRL/qvGr7l0cf59u3Tp6yfy3D10zes2zf+BbRq/J+to6QT+6Y8/i6DUPXxh/O2uCVn/v444YveYELTd79o5f9KRjto1e8xf/9JOj10ySsx65fZK6ALM++Q9fHb3mN55++ug12Vy23/NuUw9hNLfs2jN6zcMXxs8Xjjx8/F/27363w0av+YUbbh+95sv/6m9Hr/m7T/220WveGWfmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0YPQwt6q2V9Unx64LAAAAANCzVYW5VXV4VR21lgOpqqOq6rC1XCcAAAAAwGaxojC3qk6tqlck+XSSBw33XVtV9ximH1FV7xumf6WqXltV76uqz1bVcw+wvgdU1SVV9chhfZ+pqt+uqlPv4nYBAAAAAGwqhwxzhzNmf7qqPpjk3CRXJXlYa+2SZaz/lCT/JsnpSV48e+ZtVT04yZ8mOau19rFhfQ9LcnWS11TVB4e6a3oGMAAAAABAjxaWMc8Xk1ye5NmttatXuP6/aK3tSrKrqr6U5KTh/nsmeUuSH2+tXbVv5tbaTUlek6Uw99Qk5yU5J8mxK6wLAAAAALCpLOcyC2cm+XySN1XVi6rq5P0e3zOznm37PbZrZnpvvhYefyXJ3yc5Y/9iwz9Ie3GSP0vyuaH+v1JVZ1fVzqraed65O5axGQAAAAAA/TrkmbmttYuSXFRVJyb5ySRvqarrs3Sm7rVJrk3y8CR/meSpy6x7R5IfS/KOqrq5tfbHVbU9S2fl3iPJHyV5TGvty3cyrh1JdiTJ7XvSllkXAAAAAKBLy7nMQpJkCFbPSXJOVZ2epTNtk+RXk5xXVS9J8r4VrO+WqvqhJO+sqpuTXJLkl1prH13uOgAAAAAA5sWyw9xZs4Fra+0DSR50gHl+Zb/vHzrz7UOH+25M8siZ+z+3mvEAAAAAAGx2y7lmLgAAAAAAExPmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANABYS4AAAAAQAeEuQAAAAAAHRDmAgAAAAB0QJgLAAAAANCBaq1NPYa77PY9GX0jFid43rZUjV5zKn98yd+PXvMnHvYNo9fcumX8ffrlm+4YvebvXfx3o9f8lSc+aPSa2xYyNy/SKfou6+cfv3L76DUf88K/HL3m3/7uj41e87Y79o5ec6q3C9sO2zp+zTnpu3oud9XexWkOoSne6/7aRZ8ZveaXb909es1zfvQho9ecl5576+7xf9mf4nf9TRAFLduNt47/O/Aj//PbR6/5N6/60dFrTpGN3XjL+D33+KMOH73mkYcdvOc6MxcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPdhrlVdXZV7ayqneedu2Pq4QAAAAAArKuFqQewWq21HUl2JMnte9ImHg4AAAAAwLra8GfmVtXbq+q+U48DAAAAAGBKG/7M3Nbak6ceAwAAAADA1Db8mbkAAAAAAAhzAQAAAAC6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOjAwtQDWAuLrU09hFEsLk6znbv3jl/3ISccN3rNxcXRS2brBB+n3LZ77+g179gz/pM7TV+oCWpO47Y7xj+OFraM//zedPue0WtO8dx+7obbRq+582U/OHrN3RP0olt2jb8/b57guE2Sex17xOg1ty1sHb3mFL5ww+2j1zzpuPH359YJ+vwU76//6GN/N3rNZ37n/UevuWT8N7s/810nj15zip/d//TVXaPXvP8J4/eFKXzmizePXvMbTjhy9JpHHDbNuX17JsgXFraMv61v/oXvHb3mFO8Bp/jZPYXPfumW0Ws+5H5HHfQxZ+YCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdGDXMraqnV9Uvj1kTAAAAAGAzWNcwt6oOr6qjZu56UpILlzkvAAAAAACDdQlzq+rUqnpFkk8nedBwXyU5Lcknquq7q+rS4XZJVR2T5PgkV1bVH1bVI9djXAAAAAAAvVqzMLeqjqqqn66qDyY5N8lVSR7WWrtkmOU7klzWWmtJXpDkP7bWTkvy2CS3tdauS/LgJO9N8tIh5H1uVZ2wVmMEAAAAAOjVWp6Z+8Ukz0ry7NbaGa2181prN808/gNJ/nKY/lCSV1bVc5PcvbW2J0laa7taa3/SWntikqckeUKSL1TVfddwnAAAAAAA3VnLMPfMJJ9P8qaqelFVnbzf409MclGStNZeluTZSY5M8qGqOmXfTFV1r6p6fpI/T7I1yTOSXLd/sao6u6p2VtXO175mxxpuBgAAAADAxrOwVitqrV2U5KKqOjHJTyZ5S1Vdn6XQ9oYkC621LydJVX1za+2KJFcM18c9paq+mOR1SU5J8j+TPLm19vk7qbcjyY4kuXV3a2u1HQAAAAAAG9Gahbn7DIHtOUnOqarTk+xN8v1J3jUz2/Oq6nuSLCa5MkuXX9iW5FVJ3jtcVxcAAAAAgMGah7mzWmsfTZKqenGS18zc/3MHmH1Xkves53gAAAAAAHq1rmHuPq21Z49RBwAAAABgs1rLf4AGAAAAAMA6EeYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHRAmAsAAAAA0AFhLgAAAABAB4S5AAAAAAAdEOYCAAAAAHSgWmtTj2FSVXV2a22HmmqquTHrTrWtrI95OYbmpeZUddXcXDVZP/qCmmqqybjm5ThSc3PVnKruvNRcD87MTc5WU001N3TdqbaV9TEvx9C81JyqrpqbqybrR19QU001Gde8HEdqbq6aU9Wdl5prTpgLAAAAANABYS4AAAAAQAeEuckU18pQU80ea05Vt/vr2fB15uUYmpeaU9VVc3PVZP3oC2qqqSbjmpfjSM3NVXOquvNSc83N/T9AAwAAAADogTNzAQAAAAA6IMzdxKrqwxPUvG9VXTBMP76q3jZM/0hV/eKI4/ilsWqthap6XlXdbRnz3bOq/m9VXVJVj62qn6iqT1XVe1dQ6/yqOvMA9988fP2XfTiVqnp6Vf3ylGOAldJz+6Lvft049Fy6NHbf3Sg9d6jZVd/Vc//VWPRduuO9bj82Qs8dHtsQfXcz9lxh7ibWWnv0BDW/0Fr7Vy/k1tpbW2svG3EoXTXbJM9Lcshmm+T7klzRWvuO1toHkjwryXNaa9+zVgM52D5cT1V1eFUdNXPXk5JcuMx5YUPQc7vzvMxp39Vz2SzG7rsbqOcm/fXd52VOe26i77I5eK/bledlg/TcxHvd9TC3YW5VvbmqPl5VV1bV2Wu0zu1VdfXwycRnqur1VfWEqvpQVf11VZ0+3D4yfPLx4ap68LDsWVX1pqq6cJj35Wswnn2fgtynqt5fVZdW1Ser6rHLWPaoqvqLqrpsWOZpVXVtVf3GsJ6dVfWdVfWOqvrbqvqZmefgkwdY31lV9eph+vyqetWw/Z/d9ylOVW2pqt8fnsN3VtXbD/YJz37r/rp9WVUvS3LkMM7Xr/BpW5HVHEcHeG5fnOS+Sd677xOwfftumD5zeM5OS/LyJE8Ztu3FSc5Icl5V/VZVbR2+fqyqLq+qfz8sX1X16qr6dFW9K8m9DjG+f9mHVbWtqv6oqq4YjtnvGe5fk+O1qk6tqlck+XSSB+0bb5LTknyiqr572NZLh/rHJDk+yZVV9YdV9cjV1GUaa9139Vw9dwXL6bvRc+fNZu+5w3pX1Xd76rnDsl31XT3362rpu3NirXvusM4N1XdX23OHZbrpu3ru2vbcYRnvdddaa20ub0lOGL4emeSTSU5cg3VuT7InybdlKSj/eJLXJqkkT0ny5iTHJlkY5n9Ckj8dps9K8tkkxyXZluTvktz/Lo7n5uHr85P88jC9Nckxy1j2qUnOnfn+uCTXJvnZ4fvfSXJ5kmOS3DPJdTPPwSeH6ccnedvM9r16mD4/yRuH5+hbk/zNcP+ZSd4+3H/vJDckOXM1+3Lftm/E4+hOntt77L/vZp6X8/d/Hofv35fkEcP02UleOEwfkWRnkm9K8uNJ3jns+/smufFAz+vM8TK7D5+f5LXD9ClJ/n44Pld9vCY5KslPJ/ngcHvW7DGZ5DuT/I9h+s+TPGaYPjpfe+0ckeTpSS5KckmS5+7bF24b97aa18sh1rc9eu7s6/Xx0XNX+vxu+r4bPXdub6t9vdzJ+rZnA/XcYb2r6rt30hM2XM892L7MBu67d/L8bvqeO6xH353D22peK8tY5/ZsoL4b73U35HF0J8/tpD13v2Nmdj96r7sGt4XMr+dW1Y8N0/dP8sAkX16D9V7TWrsiSarqyiTvbq21qroiSwfwcUleV1UPTNKSHDaz7Ltba18Zlr0qyclJPrcGY/pYktdW1WFJ3txau3QZy1yR5BVV9ZtZapgfWPpAI2+defzo1tpNSW6qql1VdfcVjOnNrbXFJFdV1UnDfWckeeNw/z/W8q/TcqB9OZbVHEcHe27vqicmedjMp43HDeN5XJL/3Vrbm+QLVfWeFazzjCS/mySttaur6u8yfMKV1R+vX8zSD+pnt9auPsDjP5DkL4fpDyV55fAJ6Jtaa/8wjGVXkj9J8idV9Y1JXp3k5VX1gNbaF1awfYxrPfqunrs889xzk/nuu3ru/JqXnpusvO/21HOT/vruPPfcRN+dV/KFO9dT39Vzl6xHz028110Tc3mZhap6fJY+tXpUa+3bs5S8b1uj1e+amV6c+X4xyUKSlyR5b2vtoUl+eL+6s8vuHea/y1pr78/SC+7zSc6vqp9axjKfydInGFck+a9V9aL9xji7bfu+X8l4Z5dddadZ5325LrXv5Ln9utlmppe7PZXk51prpw23b2qtXbTMZVdjtcfrmVk6Ft9UVS+qqpP3e/yJWfpELG3pOkjPztInkx+qqlP2zVRV96qq52fp07WtSZ6R5LrVbAjrbx1fq3ru8sxtz03mvu/quXNonnpusvK+20vPTfrsu3PecxN9d+7IF7zXXQt6bhLvdZdtLsPcLH2icENr7dZh533XyLU/P0yfNUbB4WC+rrV2bpLXZOmFfqhl7pvk1tba/0ryW8tZZg18KMlTa+naNidl6c8oDuVg+3L38EnhelrVcXSQ5/amLP1JyT7X1dL1XrYk+bEDrOZA3pHkZ/dtd1U9qJYu5P3+JE+rpWve3CfJSi5m/oEkz9y3viTfmKXrz6xaa+2i1trTkjw2yVeSvKWq3lVL19E5Lkt/6vDloeY3t9auaK39ZpY+AT6lqo6rqjcP27UtyZNbaz/YWnvT8OkgG9NUfVfPPbi56LnJfPddPXduzU3PTVbedzvquUmHfXeee26i784p+cKhl+ml7+q5X7MePTfxXndNzOtlFi5M8jNV9aksHTQXj1j75Vn6M4gXJvmLkWo+PskvVNXuJDcnOeQnZ1m6Ls9vVdVikt1JfjbJBes2wiV/mqX/pnhVlk6l/0SWXox35mD7ckeSy6vqE621Z67TeFd7HB3ouX1Ukgur6gtt6T9H/mKStyX5pyxdm+boZaz3NVn6U5tPVFUNy/5okj9L8r1Zel7/PslHljnOJPn9JH9QS3/GsyfJWa21XbUGf7YxNNRzkpxTVadn6ZO370/yrpnZnldLF0RfTHJllv48YluSV2XpE+gWejFV39VzD25eem6i7+q582eeem6y8r7bS89N+uy7c99zE313zsgXDq2Xvqvnfs169NzEe901UR2NlTlQVUe31m6uqhOTfDRLF6f+x6nHxTiq6jVJXtNaG/MNEMwtPXe+6bkwLj0XfRfGpe/Ot83cc4W5bChV9b4kd09yeJKXt9bOn3I8AJuZngswHj0XYFz6LpuVMBcAAAAAoAPz+g/QAAAAAAC6IswFAAAAAOiAMBcAAAAAoAPCXAAAAACADghzAQAAAAA6IMwFAAAAAOjA/w9NeQeM839ZAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1728x864 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_idx = 6\n",
    "\n",
    "source = vars(train_data.examples[example_idx])['src']\n",
    "target = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "predicted, attention_scores = greedy_decode(model, source)\n",
    "\n",
    "print(f'source: {source}\\n')\n",
    "print(f'target: {target}\\n')\n",
    "print(f'predicted: {predicted}\\n')\n",
    "\n",
    "plot_attention_scores(source, predicted, attention_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
